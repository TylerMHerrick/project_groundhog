{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd #For working with data tables and dataframes\n",
        "import numpy as np #Fro numerical operations\n",
        "import matplotlib.pyplot as plt #For making plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The power of the LSTM is in its cell. The cell, in an RNN, is basically the fundamental building block that processes sequential data. It takes in both the current input and the previous cell's output (the hidden state) as input,  and produces a new output and hidden state. \n",
        "\n",
        "The gates in an LSTM are what allows it to maintain a long and short term memory. There are 3. \n",
        "\n",
        "The Input Gate decides how much new information to keep in the cell state. It uses a sigmoid function tofilter incoming data, determining what weights and biases need to be updated.\n",
        "\n",
        "The Forget Gate determines how much old information to remove from the cell state. It also uses a sigmoid function to review current inputs and past outputs, and decides wether to retain or discard previous states. The goal is to keep the network free form unnecessary/irrelivant data/\n",
        "\n",
        "The Output Gate manages what the next hidden layer or the output will receive from the cell state. It uses tanh function on the filtered cell state to scale the values, deciding, based on the sigmoid's state what should be passed onto the output.\n",
        "\n",
        "This will be shown later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "WeightInitializer\n",
        "- Blueprint for initializing weights for the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WeightInitializer: \n",
        "\n",
        "    #setup function that runs when yyou create a new weight initializer. It remembers the method you want to use for initializing weights, an ddefaults to 'random' if you don't specify one.\n",
        "\n",
        "    def __init__(self, method='random'): \n",
        "        self.method = method\n",
        "\n",
        "    #This function creates the actual weights. The \"shape\" tells it how many weights to create and how to arrange them\n",
        "\n",
        "    def initialize(self, shape):\n",
        "        if self.method == 'random':\n",
        "            return np.random.randn(*shape) #Creates random numbers from a bell curve\n",
        "        elif self.method == 'xavier':\n",
        "            return np.random.randn(*shape) / np.sqrt(shape[0]) #Divides those random numbers by the square root of the first dimension - this helps prevent numbers from getting too big or small\n",
        "        elif self.method == 'he':\n",
        "            return np.random.randn(*shape) * np.sqrt(2. / shape[0]) #Multiplies random numbers by a specific factor\n",
        "        elif self.method == 'uniform':\n",
        "            return np.random.uniform(-1, 1, shape) #Creates random numbers evenly spread between -1 and 1\n",
        "        else:\n",
        "            raise ValueError(\"Unknown initialization method: {}\".format(self.method))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PlotManager\n",
        "- Blueprint for plotting loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PlotManager:\n",
        "\n",
        "    #This sets up a figure with space for 3 graphs stacked vertically, sized 6 inches wide by 4 inches tall.\n",
        "\n",
        "    def __init__(self):\n",
        "        self.fig, self.ax = plt.subplots(3, 1, figsize=(6, 4))\n",
        "\n",
        "    #This function draws two lines on a graph: One line showing how training loss changed over time. Another line showing validation loss (how well the model performs on data it hasn't seen)\n",
        "\n",
        "    def plot_losses(self, train_losses, val_losses):\n",
        "        self.ax.plot(train_losses, label='Training Loss')\n",
        "        self.ax.plot(val_losses, label='Validation Loss')\n",
        "        self.ax.set_title('Training and Validation Losses')\n",
        "        self.ax.set_xlabel('Epoch')\n",
        "        self.ax.set_ylabel('Loss')\n",
        "        self.ax.legend()\n",
        "\n",
        "    #shows the plots\n",
        "\n",
        "    def show_plots(self):\n",
        "        plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EarlyStopping\n",
        "- Blueprint for early stopping after a given epoch, in order to prevent overfitting. \n",
        "- This class monitors the validation loss and stops training if it does not improve for a specified number of epochs (patience).\n",
        "- It can also print messages when the loss does not improve, depending on the verbose flag.\n",
        "Args:\n",
        "- patience (int): Number of epochs to wait before stopping the training. Default is 7.\n",
        "- verbose (bool): If True, prints a message for each epoch where the loss does not improve.\n",
        "- delta (float): Minimum change in the monitored quantity to qualify as an improvement. Default is 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        self.patience = patience #Number of epochs to wait before stopping\n",
        "        self.verbose = verbose #If True, prints messages when the loss does not improve\n",
        "        self.counter = 0 #Counter for how many epochs the loss has not improved\n",
        "        self.best_score = None #Best score seen so far\n",
        "        self.early_stop = False #Flag to indicate if training should stop\n",
        "        self.delta = delta #Minimum change in the monitored quantity to qualify as an improvement\n",
        "\n",
        "    #This function is called at the end of each epoch to check if the model should stop training based on the validation loss.\n",
        "    #If the validation loss does not improve for a number of epochs equal to patience, it sets early_stop to True.\n",
        "    #If verbose is True, it prints a message indicating that the loss did not improve.\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        #Determines if the model should stop training.\n",
        "\n",
        "        # Args: val_loss (float): The loss of the model on the validation set.\n",
        "        \n",
        "        score = -val_loss #flips the sign of the validation loss to make it a score (lower loss is better)\n",
        "\n",
        "        if self.best_score is None: \n",
        "            self.best_score = score # self.best_score is set to the first score seen\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1 # If the score has not improved by at least delta, increment the counter\n",
        "\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True # If the counter exceeds patience, set early_stop to True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0 # If the score has improved, reset the counter to 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Class for LSTM Network\n",
        "\n",
        "    - input_size: int, dimensionality of input space\n",
        "    - hidden_size: int, number of LSTM units\n",
        "    - output_size: int, dimensionality of output space\n",
        "    - init_method: str, weight initialization method (default: 'xavier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTM:\n",
        "    \"\"\"\n",
        "    Enhanced Long Short-Term Memory (LSTM) network with better numerical stability.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size: int, dimensionality of input space\n",
        "    - hidden_size: int, number of LSTM units\n",
        "    - output_size: int, dimensionality of output space\n",
        "    - init_method: str, weight initialization method (default: 'xavier')\n",
        "    - dropout_rate: float, dropout rate for regularization (default: 0.0)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, init_method='xavier', dropout_rate=0.0):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.weight_initializer = WeightInitializer(method=init_method)\n",
        "\n",
        "        # Initialize weights with proper scaling\n",
        "        scale_factor = 1.0 / np.sqrt(hidden_size)\n",
        "        \n",
        "        # LSTM gate weights\n",
        "        self.wf = self.weight_initializer.initialize((hidden_size, hidden_size + input_size))\n",
        "        self.wi = self.weight_initializer.initialize((hidden_size, hidden_size + input_size))\n",
        "        self.wo = self.weight_initializer.initialize((hidden_size, hidden_size + input_size))\n",
        "        self.wc = self.weight_initializer.initialize((hidden_size, hidden_size + input_size))\n",
        "\n",
        "        # Initialize biases - forget gate bias to 1 for better gradient flow\n",
        "        self.bf = np.ones((hidden_size, 1))  # Start with 1 instead of 0\n",
        "        self.bi = np.zeros((hidden_size, 1))\n",
        "        self.bo = np.zeros((hidden_size, 1))\n",
        "        self.bc = np.zeros((hidden_size, 1))\n",
        "\n",
        "        # Output layer\n",
        "        self.why = self.weight_initializer.initialize((output_size, hidden_size)) * scale_factor\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "        # For tracking during training\n",
        "        self.training = True\n",
        "\n",
        "        self.scale_factor = 1.0 / np.sqrt(hidden_size)  # Scale factor for weight initialization\n",
        "\n",
        "    def set_training(self, training):\n",
        "        \"\"\"Set training mode.\"\"\"\n",
        "        self.training = training\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(z):\n",
        "        \"\"\"Numerically stable sigmoid function.\"\"\"\n",
        "        z = np.clip(z, -500, 500)  # Prevent overflow\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    @staticmethod\n",
        "    def tanh(z):\n",
        "        \"\"\"Numerically stable tanh function.\"\"\"\n",
        "        z = np.clip(z, -500, 500)  # Prevent overflow\n",
        "        return np.tanh(z)\n",
        "\n",
        "    @staticmethod\n",
        "    def dsigmoid(y):\n",
        "        \"\"\"Derivative of sigmoid.\"\"\"\n",
        "        return y * (1 - y)\n",
        "\n",
        "    @staticmethod\n",
        "    def dtanh(y):\n",
        "        \"\"\"Derivative of tanh.\"\"\"\n",
        "        return 1 - y * y\n",
        "\n",
        "    def apply_dropout(self, x, rate):\n",
        "        \"\"\"Apply dropout during training.\"\"\"\n",
        "        if self.training and rate > 0:\n",
        "            mask = np.random.binomial(1, 1-rate, x.shape) / (1-rate)\n",
        "            return x * mask\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, return_sequences=False):\n",
        "        \"\"\"\n",
        "        Enhanced forward pass with better numerical stability.\n",
        "        \n",
        "        Parameters:\n",
        "        - x: np.ndarray, input sequences (time_steps, features) or (batch, time_steps, features)\n",
        "        - return_sequences: bool, whether to return all hidden states or just the last one\n",
        "        \n",
        "        Returns:\n",
        "        - output: np.ndarray, predictions\n",
        "        - caches: list, cached values for backpropagation\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        # Handle both 2D and 3D inputs\n",
        "        if x.ndim == 3:\n",
        "            # Batch processing - for now, process first sample\n",
        "            x = x[0]  # Take first sample in batch\n",
        "        \"\"\"\n",
        "        caches = []\n",
        "        h_prev = np.zeros((self.hidden_size, 1))\n",
        "        c_prev = np.zeros((self.hidden_size, 1))\n",
        "        \n",
        "        all_outputs = []\n",
        "        \n",
        "        for t in range(x.shape[0]):\n",
        "            x_t = x[t].reshape(-1, 1)\n",
        "            combined = np.vstack((h_prev, x_t))\n",
        "\n",
        "            # Gate computations with numerical stability\n",
        "            f = self.sigmoid(np.dot(self.wf, combined) + self.bf)\n",
        "            i = self.sigmoid(np.dot(self.wi, combined) + self.bi)\n",
        "            o = self.sigmoid(np.dot(self.wo, combined) + self.bo)\n",
        "            c_candidate = self.tanh(np.dot(self.wc, combined) + self.bc)\n",
        "\n",
        "            # Cell state update\n",
        "            c = f * c_prev + i * c_candidate\n",
        "            c = np.clip(c, -10, 10)  # Prevent exploding cell state\n",
        "            \n",
        "            # Hidden state\n",
        "            h = o * self.tanh(c)\n",
        "            h = self.apply_dropout(h, self.dropout_rate)\n",
        "\n",
        "            # Cache for backpropagation\n",
        "            cache = (h_prev, c_prev, f, i, o, c_candidate, x_t, combined, c, h)\n",
        "            caches.append(cache)\n",
        "\n",
        "            # Update for next timestep\n",
        "            h_prev, c_prev = h, c\n",
        "            \n",
        "            if return_sequences:\n",
        "                all_outputs.append(h.copy())\n",
        "\n",
        "        # Final output\n",
        "        if return_sequences:\n",
        "            # Return outputs for all timesteps\n",
        "            outputs = np.array(all_outputs).squeeze()\n",
        "            y = np.dot(self.why, outputs[-1].reshape(-1, 1)) + self.by\n",
        "        else:\n",
        "            # Return only final output\n",
        "            y = np.dot(self.why, h) + self.by\n",
        "\n",
        "        return y, caches\n",
        "\n",
        "    def backward(self, dy, caches, clip_value=5.0):\n",
        "        \"\"\"Enhanced backward pass with gradient clipping.\"\"\"\n",
        "        # Initialize gradient accumulators\n",
        "        dWf = np.zeros_like(self.wf)\n",
        "        dWi = np.zeros_like(self.wi) \n",
        "        dWo = np.zeros_like(self.wo)\n",
        "        dWc = np.zeros_like(self.wc)\n",
        "        \n",
        "        dbf = np.zeros_like(self.bf)\n",
        "        dbi = np.zeros_like(self.bi)\n",
        "        dbo = np.zeros_like(self.bo)\n",
        "        dbc = np.zeros_like(self.bc)\n",
        "        \n",
        "        dWhy = np.zeros_like(self.why)\n",
        "        dby = np.zeros_like(self.by)\n",
        "\n",
        "        # Ensure proper shape\n",
        "        dy = dy.reshape(self.output_size, -1)\n",
        "        dh_next = np.zeros((self.hidden_size, 1))\n",
        "        dc_next = np.zeros((self.hidden_size, 1))\n",
        "\n",
        "        # Backward through time\n",
        "        for idx, cache in enumerate(reversed(caches)):\n",
        "            h_prev, c_prev, f, i, o, c_candidate, x_t, combined, c, h = cache\n",
        "\n",
        "            # Output layer gradients (only for last timestep)\n",
        "            if idx == 0:\n",
        "                dWhy += np.dot(dy, h.T)\n",
        "                dby += dy\n",
        "                dh = np.dot(self.why.T, dy) + dh_next\n",
        "            else:\n",
        "                dh = dh_next\n",
        "\n",
        "            # Cell state gradient\n",
        "            dc = dc_next + (dh * o * self.dtanh(self.tanh(c)))\n",
        "\n",
        "            # Gate gradients\n",
        "            df = dc * c_prev * self.dsigmoid(f)\n",
        "            di = dc * c_candidate * self.dsigmoid(i)\n",
        "            do = dh * self.tanh(c) * self.dsigmoid(o)\n",
        "            dc_candidate = dc * i * self.dtanh(c_candidate)\n",
        "\n",
        "            # Weight gradients\n",
        "            dWf += np.dot(df, combined.T)\n",
        "            dWi += np.dot(di, combined.T)\n",
        "            dWo += np.dot(do, combined.T)\n",
        "            dWc += np.dot(dc_candidate, combined.T)\n",
        "\n",
        "            # Bias gradients\n",
        "            dbf += df\n",
        "            dbi += di\n",
        "            dbo += do\n",
        "            dbc += dc_candidate\n",
        "\n",
        "            # Gradients for next iteration\n",
        "            dcombined = (np.dot(self.wf.T, df) + np.dot(self.wi.T, di) + \n",
        "                        np.dot(self.wo.T, do) + np.dot(self.wc.T, dc_candidate))\n",
        "            \n",
        "            dh_next = dcombined[:self.hidden_size]\n",
        "            dc_next = f * dc\n",
        "\n",
        "        # Collect gradients\n",
        "        gradients = (dWf, dWi, dWo, dWc, dbf, dbi, dbo, dbc, dWhy, dby)\n",
        "\n",
        "        # Apply gradient clipping\n",
        "        clipped_gradients = []\n",
        "        for grad in gradients:\n",
        "            clipped_grad = np.clip(grad, -clip_value, clip_value)\n",
        "            clipped_gradients.append(clipped_grad)\n",
        "\n",
        "        return (dWf, dWi, dWo, dWc, dbf, dbi, dbo, dbc, dWhy, dby)\n",
        "\n",
        "    def update_params(self, grads, learning_rate):\n",
        "        \"\"\"Update parameters with gradients.\"\"\"\n",
        "        dWf, dWi, dWo, dWc, dbf, dbi, dbo, dbc, dWhy, dby = grads\n",
        "\n",
        "        # Update weights\n",
        "        self.wf -= learning_rate * dWf\n",
        "        self.wi -= learning_rate * dWi\n",
        "        self.wo -= learning_rate * dWo\n",
        "        self.wc -= learning_rate * dWc\n",
        "\n",
        "        # Update biases\n",
        "        self.bf -= learning_rate * dbf\n",
        "        self.bi -= learning_rate * dbi\n",
        "        self.bo -= learning_rate * dbo\n",
        "        self.bc -= learning_rate * dbc\n",
        "\n",
        "        # Update output layer\n",
        "        self.why -= learning_rate * dWhy\n",
        "        self.by -= learning_rate * dby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTMTrainer:\n",
        "    \"\"\"\n",
        "    Enhanced trainer for LSTM with better monitoring and learning rate scheduling.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, learning_rate=0.001, patience=15, verbose=True, delta=1e-6):\n",
        "        self.model = model\n",
        "        self.initial_learning_rate = learning_rate\n",
        "        self.learning_rate = learning_rate\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.early_stopping = EarlyStopping(patience, verbose, delta)\n",
        "        self.verbose = verbose\n",
        "        \n",
        "        # Learning rate scheduling\n",
        "        self.lr_scheduler = {\n",
        "            'factor': 0.5,\n",
        "            'patience': 5,\n",
        "            'min_lr': 1e-6,\n",
        "            'wait': 0,\n",
        "            'best_loss': np.inf\n",
        "        }\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"Compute mean squared error loss with small epsilon for numerical stability.\"\"\"\n",
        "        mse = np.mean((y_pred - y_true) ** 2)\n",
        "        return mse\n",
        "\n",
        "    def compute_metrics(self, y_pred, y_true):\n",
        "        \"\"\"Compute additional metrics for monitoring.\"\"\"\n",
        "        mse = np.mean((y_pred - y_true) ** 2)\n",
        "        mae = np.mean(np.abs(y_pred - y_true))\n",
        "        \n",
        "        # R-squared\n",
        "        ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "        r2 = 1 - (ss_res / (ss_tot + 1e-8))\n",
        "        \n",
        "        return {'mse': mse, 'mae': mae, 'r2': r2}\n",
        "\n",
        "    def update_learning_rate(self, val_loss):\n",
        "        \"\"\"Update learning rate based on validation loss.\"\"\"\n",
        "        if val_loss < self.lr_scheduler['best_loss']:\n",
        "            self.lr_scheduler['best_loss'] = val_loss\n",
        "            self.lr_scheduler['wait'] = 0\n",
        "        else:\n",
        "            self.lr_scheduler['wait'] += 1\n",
        "            \n",
        "        if self.lr_scheduler['wait'] >= self.lr_scheduler['patience']:\n",
        "            old_lr = self.learning_rate\n",
        "            self.learning_rate = max(\n",
        "                self.learning_rate * self.lr_scheduler['factor'],\n",
        "                self.lr_scheduler['min_lr']\n",
        "            )\n",
        "            if self.verbose and old_lr != self.learning_rate:\n",
        "                print(f\"Reducing learning rate from {old_lr:.6f} to {self.learning_rate:.6f}\")\n",
        "            self.lr_scheduler['wait'] = 0\n",
        "\n",
        "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=100, \n",
        "              batch_size=32, clip_value=5.0, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Enhanced training with better batch processing and monitoring.\n",
        "        \"\"\"\n",
        "        self.model.set_training(True)\n",
        "        \n",
        "        # Create validation split if not provided\n",
        "        if X_val is None and validation_split > 0:\n",
        "            split_idx = int(len(X_train) * (1 - validation_split))\n",
        "            X_val, y_val = X_train[split_idx:], y_train[split_idx:]\n",
        "            X_train, y_train = X_train[:split_idx], y_train[:split_idx]\n",
        "            if self.verbose:\n",
        "                print(f\"Created validation split: {len(X_train)} train, {len(X_val)} val samples\")\n",
        "\n",
        "        best_val_loss = np.inf\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            self.model.set_training(True)\n",
        "            epoch_losses = []\n",
        "            \n",
        "            # Shuffle training data\n",
        "            indices = np.random.permutation(len(X_train))\n",
        "            X_train_shuffled = X_train[indices]\n",
        "            y_train_shuffled = y_train[indices]\n",
        "            \n",
        "            # Mini-batch training\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                batch_end = min(i + batch_size, len(X_train))\n",
        "                batch_X = X_train_shuffled[i:batch_end]\n",
        "                batch_y = y_train_shuffled[i:batch_end]\n",
        "                batch_grads = None\n",
        "                batch_loss = 0\n",
        "                \n",
        "                batch_losses = []\n",
        "                \n",
        "                for x, y_true in zip(batch_X, batch_y):\n",
        "                    # Forward pass\n",
        "                    y_pred, caches = self.model.forward(x)\n",
        "                    loss = self.compute_loss(y_pred, y_true.reshape(-1, 1))\n",
        "                    batch_losses.append(loss)\n",
        "                    \n",
        "                    # Backward pass\n",
        "                    dy = y_pred - y_true.reshape(-1, 1)\n",
        "                    grads = self.model.backward(dy, caches, clip_value=clip_value)\n",
        "                    self.model.update_params(grads, self.learning_rate)\n",
        "\n",
        "                    if batch_grads is None:\n",
        "                        batch_grads = grads\n",
        "                    else:\n",
        "                        batch_grads = [g_acc + g for g_acc, g in zip(batch_grads, grads)]\n",
        "                \n",
        "                epoch_losses.extend(batch_losses)\n",
        "\n",
        "                batch_grads = [g / len(batch_X) for g in batch_grads]  # Average gradients\n",
        "                self.model.update_params(batch_grads, self.learning_rate)\n",
        "\n",
        "                for i in range(len(batch_grads)):\n",
        "                    batch_grads[i] = np.clip(batch_grads[i], -clip_value, clip_value)  # Clip gradients\n",
        "            \n",
        "            # Record training loss\n",
        "            avg_train_loss = np.mean(epoch_losses)\n",
        "            self.train_losses.append(avg_train_loss)\n",
        "            \n",
        "            # Validation phase\n",
        "            if X_val is not None and y_val is not None:\n",
        "                val_loss, val_metrics = self.validate(X_val, y_val)\n",
        "                self.val_losses.append(val_loss)\n",
        "                \n",
        "                # Update learning rate\n",
        "                self.update_learning_rate(val_loss)\n",
        "                \n",
        "                if self.verbose:\n",
        "                    print(f'Epoch {epoch + 1:3d}/{epochs} - '\n",
        "                          f'Train Loss: {avg_train_loss:.6f}, '\n",
        "                          f'Val Loss: {val_loss:.6f}, '\n",
        "                          f'Val R²: {val_metrics[\"r2\"]:.4f}, '\n",
        "                          f'LR: {self.learning_rate:.6f}')\n",
        "                \n",
        "                # Early stopping check\n",
        "                self.early_stopping(val_loss)\n",
        "                if self.early_stopping.early_stop:\n",
        "                    if self.verbose:\n",
        "                        print(\"Early stopping triggered!\")\n",
        "                    break\n",
        "                    \n",
        "                # Save best model weights (simplified)\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    \n",
        "            else:\n",
        "                if self.verbose:\n",
        "                    print(f'Epoch {epoch + 1:3d}/{epochs} - Train Loss: {avg_train_loss:.6f}')\n",
        "\n",
        "        self.model.set_training(False)\n",
        "        if self.verbose:\n",
        "            print(f\"Training completed. Best validation loss: {best_val_loss:.6f}\")\n",
        "\n",
        "    def validate(self, X_val, y_val):\n",
        "        \"\"\"Enhanced validation with metrics.\"\"\"\n",
        "        self.model.set_training(False)\n",
        "        \n",
        "        val_losses = []\n",
        "        predictions = []\n",
        "        actuals = []\n",
        "        \n",
        "        for x, y_true in zip(X_val, y_val):\n",
        "            y_pred, _ = self.model.forward(x)\n",
        "            loss = self.compute_loss(y_pred, y_true.reshape(-1, 1))\n",
        "            val_losses.append(loss)\n",
        "            \n",
        "            predictions.append(y_pred.flatten())\n",
        "            actuals.append(y_true.flatten())\n",
        "        \n",
        "        predictions = np.concatenate(predictions)\n",
        "        actuals = np.concatenate(actuals)\n",
        "        \n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        metrics = self.compute_metrics(predictions, actuals)\n",
        "        \n",
        "        return avg_val_loss, metrics\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Make predictions on test data.\"\"\"\n",
        "        self.model.set_training(False)\n",
        "        predictions = []\n",
        "        \n",
        "        for x in X_test:\n",
        "            y_pred, _ = self.model.forward(x)\n",
        "            predictions.append(y_pred.flatten())\n",
        "            \n",
        "        return np.array(predictions)\n",
        "\n",
        "    def plot_training_history(self, figsize=(12, 4)):\n",
        "        \"\"\"Plot training and validation loss.\"\"\"\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "        \n",
        "        # Loss plot\n",
        "        epochs = range(1, len(self.train_losses) + 1)\n",
        "        ax1.plot(epochs, self.train_losses, 'b-', label='Training Loss', alpha=0.7)\n",
        "        if self.val_losses:\n",
        "            ax1.plot(epochs, self.val_losses, 'r-', label='Validation Loss', alpha=0.7)\n",
        "        ax1.set_title('Training and Validation Loss')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Learning rate plot\n",
        "        if hasattr(self, 'lr_history'):\n",
        "            ax2.plot(epochs, self.lr_history, 'g-', alpha=0.7)\n",
        "            ax2.set_title('Learning Rate Schedule')\n",
        "            ax2.set_xlabel('Epoch')\n",
        "            ax2.set_ylabel('Learning Rate')\n",
        "            ax2.set_yscale('log')\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "        else:\n",
        "            ax2.text(0.5, 0.5, 'Learning Rate\\nHistory Not Available', \n",
        "                    ha='center', va='center', transform=ax2.transAxes)\n",
        "            ax2.set_title('Learning Rate Schedule')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing Dataset from Azure Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n",
            "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1962-01-02</td>\n",
              "      <td>4.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1962-01-03</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1962-01-04</td>\n",
              "      <td>3.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1962-01-05</td>\n",
              "      <td>4.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1962-01-08</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16575</th>\n",
              "      <td>2025-07-15</td>\n",
              "      <td>4.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16576</th>\n",
              "      <td>2025-07-16</td>\n",
              "      <td>4.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16577</th>\n",
              "      <td>2025-07-17</td>\n",
              "      <td>4.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16578</th>\n",
              "      <td>2025-07-18</td>\n",
              "      <td>4.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16579</th>\n",
              "      <td>2025-07-21</td>\n",
              "      <td>4.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15872 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date  Value\n",
              "0     1962-01-02   4.06\n",
              "1     1962-01-03   4.03\n",
              "2     1962-01-04   3.99\n",
              "3     1962-01-05   4.02\n",
              "4     1962-01-08   4.03\n",
              "...          ...    ...\n",
              "16575 2025-07-15   4.50\n",
              "16576 2025-07-16   4.46\n",
              "16577 2025-07-17   4.47\n",
              "16578 2025-07-18   4.44\n",
              "16579 2025-07-21   4.38\n",
              "\n",
              "[15872 rows x 2 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = 'b23ddd02-1d4d-4c80-8ef3-f68a97a0dab6'\n",
        "resource_group = 'MLDev'\n",
        "workspace_name = 'project_groundhog'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='Treasury')\n",
        "dataset = dataset.to_pandas_dataframe()\n",
        "dataset = dataset.dropna()  # Drop rows with NaN values\n",
        "dataset = dataset.rename(columns={'observation_date': 'Date', 'DGS10': 'Value'})\n",
        "df = dataset\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configuring Dataset into what we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimeSeriesDataset:\n",
        "    \"\"\"\n",
        "    Dataset class for time series data.\n",
        "    \n",
        "    Parameters:\n",
        "    - dataframe: pd.DataFrame, the pandas DataFrame containing your data\n",
        "    - start_date: str, start date for data retrieval (format: 'YYYY-MM-DD')\n",
        "    - end_date: str, end date for data retrieval (format: 'YYYY-MM-DD')\n",
        "    - look_back: int, number of previous time steps to include in each sample\n",
        "    - train_size: float, proportion of data to use for training (between 0 and 1)\n",
        "    - date_column: str, name of the date column (default: 'Date')\n",
        "    - value_column: str, name of the value column (default: 'Value')\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, start_date, end_date, look_back=1, train_size=0.67, \n",
        "                 date_column='Date', value_column='Value'):\n",
        "        self.dataframe = dataframe.copy()  # Make a copy to avoid modifying original\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.look_back = look_back\n",
        "        self.train_size = train_size\n",
        "        self.date_column = date_column\n",
        "        self.value_column = value_column\n",
        "        \n",
        "        # Validate inputs\n",
        "        if not 0 < train_size < 1:\n",
        "            raise ValueError(\"train_size must be between 0 and 1\")\n",
        "        if look_back < 1:\n",
        "            raise ValueError(\"look_back must be at least 1\")\n",
        "            \n",
        "        # Ensure date column is datetime\n",
        "        if not pd.api.types.is_datetime64_any_dtype(self.dataframe[date_column]):\n",
        "            print(f\"Converting {date_column} to datetime...\")\n",
        "            self.dataframe[date_column] = pd.to_datetime(self.dataframe[date_column])\n",
        "    \n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Load and preprocess the data.\n",
        "        \n",
        "        Returns:\n",
        "        - np.ndarray, training data\n",
        "        - np.ndarray, testing data\n",
        "        \"\"\"\n",
        "        # Work with a copy of the dataframe\n",
        "        df = self.dataframe.copy()\n",
        "        \n",
        "        # Filter by date range\n",
        "        start_date = pd.to_datetime(self.start_date)\n",
        "        end_date = pd.to_datetime(self.end_date)\n",
        "        \n",
        "        df = df[(df[self.date_column] >= start_date) & \n",
        "                (df[self.date_column] <= end_date)]\n",
        "        \n",
        "        if len(df) == 0:\n",
        "            raise ValueError(f\"No data found between {self.start_date} and {self.end_date}\")\n",
        "        \n",
        "        # Sort by date to ensure chronological order\n",
        "        df = df.sort_values(by=self.date_column).reset_index(drop=True)\n",
        "        \n",
        "        # Extract the value column and ensure it's numeric\n",
        "        values = df[self.value_column].astype(float).values.reshape(-1, 1)\n",
        "        \n",
        "        # Check for any NaN values\n",
        "        if np.isnan(values).any():\n",
        "            print(\"Warning: Found NaN values in data. Consider handling them.\")\n",
        "            # Option: Remove NaN values\n",
        "            # values = values[~np.isnan(values).any(axis=1)]\n",
        "        \n",
        "        # Scale the data\n",
        "        scaled_values = self.min_max_scaler(values)\n",
        "        \n",
        "        # Split into train and test\n",
        "        train_size = int(len(scaled_values) * self.train_size)\n",
        "        train_data = scaled_values[:train_size]\n",
        "        test_data = scaled_values[train_size:]\n",
        "        \n",
        "        print(f\"Data loaded: {len(scaled_values)} total samples\")\n",
        "        print(f\"Training samples: {len(train_data)}\")\n",
        "        print(f\"Testing samples: {len(test_data)}\")\n",
        "        \n",
        "        return train_data, test_data\n",
        "    \n",
        "    def min_max_scaler(self, data):\n",
        "        \"\"\"\n",
        "        Min-max scaling of the data to range [0, 1].\n",
        "        \n",
        "        Parameters:\n",
        "        - data: np.ndarray, input data\n",
        "        \n",
        "        Returns:\n",
        "        - np.ndarray, scaled data\n",
        "        \"\"\"\n",
        "        # Store min and max for potential inverse scaling later\n",
        "        self.data_min = np.min(data, axis=0)\n",
        "        self.data_max = np.max(data, axis=0)\n",
        "        \n",
        "        numerator = data - self.data_min\n",
        "        denominator = self.data_max - self.data_min\n",
        "        \n",
        "        # Add small epsilon to prevent division by zero\n",
        "        return numerator / (denominator + 1e-8)\n",
        "    \n",
        "    def inverse_scale(self, scaled_data):\n",
        "        \"\"\"\n",
        "        Inverse the min-max scaling to get original scale.\n",
        "        \n",
        "        Parameters:\n",
        "        - scaled_data: np.ndarray, scaled data\n",
        "        \n",
        "        Returns:\n",
        "        - np.ndarray, data in original scale\n",
        "        \"\"\"\n",
        "        scaled_data = scaled_data.reshape(-1, 1)  # Ensure 2D\n",
        "        return scaled_data * (self.data_max - self.data_min) + self.data_min\n",
        "    \n",
        "    def create_dataset(self, data):\n",
        "        \"\"\"\n",
        "        Create sequences for time series prediction.\n",
        "        \n",
        "        Parameters:\n",
        "        - data: np.ndarray, input data\n",
        "        \n",
        "        Returns:\n",
        "        - np.ndarray, input sequences (X)\n",
        "        - np.ndarray, target values (Y)\n",
        "        \"\"\"\n",
        "        if len(data) <= self.look_back:\n",
        "            raise ValueError(f\"Data length ({len(data)}) must be greater than look_back ({self.look_back})\")\n",
        "        \n",
        "        X, Y = [], []\n",
        "        \n",
        "        for i in range(len(data) - self.look_back):\n",
        "            # Get sequence of length look_back\n",
        "            sequence = data[i:(i + self.look_back), 0]  # Take first column\n",
        "            target = data[i + self.look_back, 0]  # Next value\n",
        "            \n",
        "            X.append(sequence)\n",
        "            Y.append(target)\n",
        "        \n",
        "        return np.array(X), np.array(Y)\n",
        "    \n",
        "    def get_train_test(self):\n",
        "        \"\"\"\n",
        "        Get the complete training and testing datasets.\n",
        "        \n",
        "        Returns:\n",
        "        - np.ndarray, training input sequences\n",
        "        - np.ndarray, training targets\n",
        "        - np.ndarray, testing input sequences  \n",
        "        - np.ndarray, testing targets\n",
        "        \"\"\"\n",
        "        # Load and split the data\n",
        "        train_data, test_data = self.load_data()\n",
        "        \n",
        "        # Create sequences\n",
        "        trainX, trainY = self.create_dataset(train_data)\n",
        "        testX, testY = self.create_dataset(test_data)\n",
        "        \n",
        "        print(f\"Training sequences: {trainX.shape}\")\n",
        "        print(f\"Testing sequences: {testX.shape}\")\n",
        "        \n",
        "        return trainX, trainY, testX, testY\n",
        "    \n",
        "    def get_data_info(self):\n",
        "        \"\"\"\n",
        "        Print information about the dataset.\n",
        "        \"\"\"\n",
        "        print(f\"Dataset shape: {self.dataframe.shape}\")\n",
        "        print(f\"Date range: {self.dataframe[self.date_column].min()} to {self.dataframe[self.date_column].max()}\")\n",
        "        print(f\"Value range: {self.dataframe[self.value_column].min():.4f} to {self.dataframe[self.value_column].max():.4f}\")\n",
        "        print(f\"Look back: {self.look_back}\")\n",
        "        print(f\"Train size: {self.train_size * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (15872, 2)\n",
            "Date range: 1962-01-02 00:00:00 to 2025-07-21 00:00:00\n",
            "Value range: 0.5200 to 15.8400\n",
            "Look back: 5\n",
            "Train size: 67.0%\n",
            "Data loaded: 15872 total samples\n",
            "Training samples: 10634\n",
            "Testing samples: 5238\n",
            "Training sequences: (10629, 5)\n",
            "Testing sequences: (5233, 5)\n",
            "Final training shape: (10629, 5, 1)\n",
            "Final testing shape: (5233, 5, 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nlstm = LSTM(input_size=1, hidden_size=hidden_size, output_size=output_size)\\n\\ntrainer = LSTMTrainer(lstm, learning_rate=1e-3, patience=50, verbose=True, delta=0.001)\\ntrainer.train(trainX, trainY, testX, testY, epochs=1000, batch_size=32)\\n\\nplot_manager = PlotManager()\\n\\n# Inside your training loop\\nplot_manager.plot_losses(trainer.train_losses, trainer.val_losses)\\n\\n# After your training loop\\nplot_manager.show_plots()\\n'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instantiate the dataset\n",
        "dataset = TimeSeriesDataset( dataframe=df, start_date='1962-01-02', end_date='2025-07-21', look_back=5)\n",
        "\n",
        "dataset.get_data_info()\n",
        "\n",
        "trainX, trainY, testX, testY = dataset.get_train_test()\n",
        "\n",
        "# Reshape for LSTM (samples, time steps, features)\n",
        "trainX = trainX.reshape(trainX.shape[0], trainX.shape[1], 1)\n",
        "testX = testX.reshape(testX.shape[0], testX.shape[1], 1)\n",
        "\n",
        "print(f\"Final training shape: {trainX.shape}\")\n",
        "print(f\"Final testing shape: {testX.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initialize the LSTM model with enhanced numerical stability\n",
        "model = LSTM(\n",
        "    input_size=1, \n",
        "    hidden_size=256, \n",
        "    output_size=1,\n",
        "    init_method='xavier',\n",
        "    dropout_rate=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch   1/100 - Train Loss: 0.019138, Val Loss: 0.026221, Val R²: -3.7716, LR: 0.001000\n",
            "Epoch   2/100 - Train Loss: 0.005884, Val Loss: 0.009399, Val R²: -0.7104, LR: 0.001000\n",
            "Epoch   3/100 - Train Loss: 0.002419, Val Loss: 0.002560, Val R²: 0.5341, LR: 0.001000\n",
            "Epoch   4/100 - Train Loss: 0.001333, Val Loss: 0.000633, Val R²: 0.8849, LR: 0.001000\n",
            "Epoch   5/100 - Train Loss: 0.001010, Val Loss: 0.000169, Val R²: 0.9693, LR: 0.001000\n",
            "Epoch   6/100 - Train Loss: 0.000880, Val Loss: 0.000057, Val R²: 0.9897, LR: 0.001000\n",
            "Epoch   7/100 - Train Loss: 0.000902, Val Loss: 0.000043, Val R²: 0.9923, LR: 0.001000\n",
            "Epoch   8/100 - Train Loss: 0.000865, Val Loss: 0.000033, Val R²: 0.9941, LR: 0.001000\n",
            "Epoch   9/100 - Train Loss: 0.000887, Val Loss: 0.000029, Val R²: 0.9947, LR: 0.001000\n",
            "Epoch  10/100 - Train Loss: 0.000845, Val Loss: 0.000030, Val R²: 0.9945, LR: 0.001000\n",
            "Epoch  11/100 - Train Loss: 0.000865, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.001000\n",
            "Epoch  12/100 - Train Loss: 0.000815, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.001000\n",
            "Epoch  13/100 - Train Loss: 0.000847, Val Loss: 0.000029, Val R²: 0.9947, LR: 0.001000\n",
            "Epoch  14/100 - Train Loss: 0.000846, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.001000\n",
            "Epoch  15/100 - Train Loss: 0.000827, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.001000\n",
            "Epoch  16/100 - Train Loss: 0.000807, Val Loss: 0.000030, Val R²: 0.9945, LR: 0.001000\n",
            "Reducing learning rate from 0.001000 to 0.000500\n",
            "Epoch  17/100 - Train Loss: 0.000784, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.000500\n",
            "Epoch  18/100 - Train Loss: 0.000803, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.000500\n",
            "Epoch  19/100 - Train Loss: 0.000795, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.000500\n",
            "Epoch  20/100 - Train Loss: 0.000788, Val Loss: 0.000028, Val R²: 0.9949, LR: 0.000500\n",
            "Epoch  21/100 - Train Loss: 0.000793, Val Loss: 0.000029, Val R²: 0.9948, LR: 0.000500\n",
            "Reducing learning rate from 0.000500 to 0.000250\n",
            "Epoch  22/100 - Train Loss: 0.000796, Val Loss: 0.000029, Val R²: 0.9947, LR: 0.000250\n",
            "Epoch  23/100 - Train Loss: 0.000796, Val Loss: 0.000028, Val R²: 0.9948, LR: 0.000250\n",
            "Epoch  24/100 - Train Loss: 0.000770, Val Loss: 0.000029, Val R²: 0.9948, LR: 0.000250\n",
            "Early stopping triggered!\n",
            "Training completed. Best validation loss: 0.000028\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = LSTMTrainer(\n",
        "    model, \n",
        "    learning_rate=0.001, \n",
        "    patience=15\n",
        ")\n",
        "trainer.train(\n",
        "    trainX, \n",
        "    trainY, \n",
        "    X_val=testX, \n",
        "    y_val=testY,\n",
        "    epochs=100,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "trainer.plot_training_history()\n",
        "predictions = trainer.predict(testX)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
